{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 安装必要的模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U requests-html\n",
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下载百度主页 到本地文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_html import HTMLSession\n",
    "session = HTMLSession()\n",
    "print(session.headers)\n",
    "url = \"https://www.daodejing.org/\"\n",
    "r=session.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.headers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.cookies.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.html.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_html import HTMLSession\n",
    "session = HTMLSession()\n",
    "url = \"https://www.daodejing.org/\"\n",
    "fileName = 'out/a.html'\n",
    "with session.get(url) as r ,open(fileName,'w',encoding = 'utf-8') as f:\n",
    "    f.write(r.text)\n",
    "    print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r.html.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_html import HTMLSession\n",
    "session = HTMLSession()\n",
    "url='https://www.daodejing.org/'\n",
    "fileName='out/a.html'\n",
    "with session.get(url) as r,open(fileName,'w',encoding='utf-8') as f:\n",
    "     f.write(r.html.text)\n",
    "     print(r.html.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获得 上师大主页所有链接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_html import HTMLSession\n",
    "session = HTMLSession()\n",
    "r = session.post(\"http://www.shnu.edu.cn/\")\n",
    "# print(r.html.links)\n",
    "s={link for link in r.html.absolute_links}\n",
    "from pprint import pprint\n",
    "pprint(s)\n",
    "    #pass\n",
    "#     print(link)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取 上师大主页学术信息 板块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_html import HTMLSession\n",
    "session = HTMLSession()\n",
    "site = session.get(\"http://www.shnu.edu.cn/\")\n",
    "\n",
    "public_notice_items = site.html.find('#wp_news_w31 > ul')\n",
    "# 根据id获取内容，使用 # 号连接，全部z拿回来的数据是一个list 对象\n",
    "\n",
    "\n",
    "\n",
    "for public_notice_item in public_notice_items:\n",
    "    public_notice_list = public_notice_item.find('a')\n",
    "    for item in public_notice_list:\n",
    "        print(item.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 上师大公告信息下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_html import HTMLSession\n",
    "site = HTMLSession().get('http://www.shnu.edu.cn/')\n",
    "public_notice_item = site.html.find('div#wp_news_w21',first=True)\n",
    "public_notice_list = public_notice_item.find('a')\n",
    "print(*[item.text for  item in public_notice_list],sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h='''\n",
    "Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\n",
    "Accept-Encoding: gzip, deflate, br\n",
    "Accept-Language: zh-CN;q=0.8\n",
    "Cache-Control: max-age=0\n",
    "Connection: keep-alive\n",
    "Host: www.edu.cn\n",
    "Sec-Fetch-Dest: document\n",
    "Sec-Fetch-Mode: navigate\n",
    "Sec-Fetch-Site: none\n",
    "Sec-Fetch-User: ?1\n",
    "Sec-GPC: 1\n",
    "Upgrade-Insecure-Requests: 1\n",
    "User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.5112.81 Safari/537.36\n",
    "'''\n",
    "print('*'*33)\n",
    "import re\n",
    "from pprint import pprint\n",
    "results=re.findall('([\\w\\-]*):\\s([\\w=+\\-;,\\.\\*\\/\\?\\(\\)\\s]*)$',h,re.MULTILINE)\n",
    "pprint(results)\n",
    "pprint(dict(results))\n",
    "hh=dict(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from requests_html import HTMLSession\n",
    "session = HTMLSession()\n",
    "site = session.get('https://www.daodejing.org/')\n",
    "top_item = site.html.xpath('/html/body/div[1]/div[5]',first=True)\n",
    "text=top_item.text\n",
    "#print(text)\n",
    "#使用正则表达式过滤掉不需要的注解信息。\n",
    "import re\n",
    "rtext=re.sub('（.*\\n*.*）|〖译文〗|\\(\\n*.*\\)','',text)\n",
    "print(rtext)\n",
    "open('out/daodejing.txt','w').write(rtext)\n",
    "\n",
    "\n",
    "#print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取搜狐新闻 特定栏目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_html import HTMLSession\n",
    "session = HTMLSession()\n",
    "site = session.get(\"https://news.sohu.com/\")\n",
    "public_notice_items = site.html.find('body > div.wrapper-box > div.main-news-wrap > div.contentA.public.area.clearfix > div.main.left > div > div.main-right.right > div > div:nth-child(3)')\n",
    "# 根据id获取内容，使用 # 号连接，全部z拿回来的数据是一个list 对象\n",
    "\n",
    "\n",
    "for public_notice_item in public_notice_items:\n",
    "    public_notice_list = public_notice_item.find('a')\n",
    "    for item in public_notice_list:\n",
    "        print(item.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取百度热搜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_html import HTMLSession\n",
    "session = HTMLSession()\n",
    "site = session.get(\"http://top.baidu.com/\")\n",
    "top_items = site.html.find('#sanRoot > main > div.hot-wrap_1nNog > div.theme-hot.category-item_1fzJW > div.list_1EDla',first = True)\n",
    "\n",
    "#sanRoot > main > div.hot-wrap_1nNog > div.theme-hot.category-item_1fzJW > div.list_1EDla\n",
    "#根据class获取内容，使用 . 号连接，first = True 表示，如果第一个元素符合要求，则只返回第一个元素，拿回来的内容是一个字符串类型的对象\n",
    "top_list = top_items.find('a')\n",
    "\n",
    "#for item in top_list[::2]:\n",
    "#    print(item.text) \n",
    "from pprint import pprint\n",
    "pprint([i.text.splitlines()[1] for i in top_list])\n",
    "\n",
    "#k=[i.text for i in top_list]\n",
    "#results=k[3::3]\n",
    "#print(results)\n",
    "#pprint([i.text.splitlines()[1] for i in top_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取百度热搜 游戏排行榜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_html import HTMLSession\n",
    "session = HTMLSession()\n",
    "site = session.get(\"http://top.baidu.com/\")\n",
    "top_items = site.html.find('#sanRoot > main > div.content-wrap_1E_gm > div:nth-child(5) > div.list_1s-Px',first = True)\n",
    "\n",
    "#sanRoot > main > div.hot-wrap_1nNog > div.theme-hot.category-item_1fzJW > div.list_1EDla\n",
    "#根据class获取内容，使用 . 号连接，first = True 表示，如果第一个元素符合要求，则只返回第一个元素，拿回来的内容是一个字符串类型的对象\n",
    "top_list = top_items.find('a')\n",
    "\n",
    "#for item in top_list[::2]:\n",
    "#    print(item.text) \n",
    "from pprint import pprint\n",
    "pprint([i.text for i in top_list])\n",
    "\n",
    "k=[i.text for i in top_list]\n",
    "results=k[1::3]\n",
    "print(results)\n",
    "#pprint([i.text.splitlines()[1] for i in top_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   获取百度电影排行榜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sanRoot > main > div.content-wrap_1E_gm > div:nth-child(2) > div.list_1s-Px\n",
    "\n",
    "from requests_html import HTMLSession\n",
    "session = HTMLSession()\n",
    "site = session.get(\"http://top.baidu.com/\")\n",
    "top_items = site.html.find('#sanRoot > main > div.content-wrap_1E_gm > div:nth-child(2) > div.list_1s-Px',first = True)\n",
    "\n",
    "#sanRoot > main > div.hot-wrap_1nNog > div.theme-hot.category-item_1fzJW > div.list_1EDla\n",
    "#根据class获取内容，使用 . 号连接，first = True 表示，如果第一个元素符合要求，则只返回第一个元素，拿回来的内容是一个字符串类型的对象\n",
    "top_list = top_items.find('a')\n",
    "\n",
    "#for item in top_list[::2]:\n",
    "#    print(item.text) \n",
    "from pprint import pprint\n",
    "pprint([i.text for i in top_list])\n",
    "\n",
    "k=[i.text for i in top_list]\n",
    "print(k[1::3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取上海市地铁 线路 (由于该网站网页结构更新，以下爬虫可能不一定运行正确）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from requests_html import HTMLSession\n",
    "import pandas as pd\n",
    "\n",
    "session = HTMLSession()\n",
    "\n",
    "\n",
    "# 把所有的路线极其url保存为字典类型的。\n",
    "def get_subway_lines_url():\n",
    "    subway_number_str_list = map(str, list(range(1, 19)) + [41])\n",
    "    subway_url_dict = dict(map(lambda x: (x, f\"http://service.shmetro.com/axlcz{x.rjust(2, '0')}/index.htm\"),\n",
    "                               subway_number_str_list))\n",
    "    subway_url_dict['浦江线'] = subway_url_dict.pop('41')\n",
    "    return subway_url_dict\n",
    "\n",
    "\n",
    "# 根据每一条线路的url，在网站上搜出对应的站点\n",
    "def get_each_line_stations(line):\n",
    "    print(f'正在爬取{line}')\n",
    "    site = session.get(line)\n",
    "    line_list = site.html.find('div.linehow', first=True)\n",
    "    #content > div.left > div.left_area > div > div > div.app_detial > div > div.linehow\n",
    "    station_list = line_list.find('a')\n",
    "    line = [station.text for station in station_list]\n",
    "    line=line[:line.index('网络示意图')]\n",
    "    print(line)\n",
    "    return pd.Series(line)\n",
    "\n",
    "\n",
    "def save_to_excel(fileName):\n",
    "    lines = get_subway_lines_url()\n",
    "    data = dict(map(lambda x, y: (x, get_each_line_stations(y)), lines.keys(), lines.values()))\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_excel(fileName)\n",
    "    print(f'爬取数据保存着{fileName}')\n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    save_to_excel('out/subway.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 改进版的上海地铁爬虫 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_html import HTMLSession\n",
    "site = HTMLSession().get('https://m.8684.cn/shanghai_dt_map')\n",
    "lines = site.html.find('li.sLink')\n",
    "lines_dict = {}\n",
    "for line in lines:\n",
    "    stations = line.find('a')\n",
    "    station = [i.text for i in stations]\n",
    "    lines_dict[station[0]] = station[1:]\n",
    "print(lines_dict)\n",
    "'''\n",
    "import pandas as pd\n",
    "df = pd.DataFrame()\n",
    "for i in lines_dict:\n",
    "    df[i] = pd.Series(lines_dict[i])\n",
    "df.to_excel('subway.xlsx')\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 批量下载网页 （繁体转简体）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_html import HTMLSession\n",
    "from pprint import pprint\n",
    "\n",
    "session = HTMLSession()\n",
    "\n",
    "r = session.get('https://www.itread01.com/study/python3-tutorial.html')\n",
    "\n",
    "# 絕對路徑鏈接 仅要python3\n",
    "\n",
    "plinks=[ i for i in r.html.absolute_links if 'python3' in i]\n",
    "\n",
    "#plinks = list(filter(lambda i: True if 'python3' in i else False, r.html.absolute_links))\n",
    "\n",
    "\n",
    "\n",
    "def url2file(url):\n",
    "\n",
    "    content_big5 = session.get(url).html.text\n",
    "    from zhconv import convert\n",
    "    contents_cn = convert(content_big5, 'zh-cn')\n",
    "    file_name = url.split('/')[-1].split('.')[0] + '.txt'\n",
    "    open(file_name, 'w', encoding='utf-8').write(contents_cn)\n",
    "    print(file_name, 'done!')\n",
    "    \n",
    "\n",
    "\n",
    "list(map(url2file, plinks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_html import HTMLSession\n",
    "\n",
    "session = HTMLSession()\n",
    "\n",
    "\n",
    "def get_urls(startPageUrl):\n",
    "    r = session.get(startPageUrl)\n",
    "    return [i for i in r.html.absolute_links if 'python3' in i]\n",
    "\n",
    "\n",
    "def url2file(url):\n",
    "    content_big5 = session.get(url).html.text\n",
    "    from zhconv import convert\n",
    "    contents_cn = convert(content_big5, 'zh-cn')\n",
    "    file_name = url.split('/')[-1].split('.')[0] + '.txt'\n",
    "    print(contents_cn, file=open(file_name, 'w', encoding='utf-8'))\n",
    "    print(file_name, 'done!')\n",
    "    return file_name\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    startPageUrl = 'https://www.itread01.com/study/python3-tutorial.html'\n",
    "    result = list(map(url2file, get_urls(startPageUrl)))\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 批量下载图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_html import HTMLSession\n",
    "session = HTMLSession()\n",
    "url=\"https://pic.netbian.com\"\n",
    "r = session.get(url)\n",
    "selector='#main > div.slist'\n",
    "about = r.html.find(selector, first=True)\n",
    "img_Elements=about.find('img')\n",
    "\n",
    "img_url_lst=[url+i.attrs['src'] for i in img_Elements]\n",
    "for img_url in img_url_lst:\n",
    "    name =\"out/\"+img_url.split('/')[-1]\n",
    "    f = open(name,'wb')\n",
    "    f.write(session.get(img_url).content)\n",
    "    print(f'downloaded file:{name} ')\n",
    "    f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_html import HTMLSession\n",
    "\n",
    "session = HTMLSession()\n",
    "url=\"https://pic.netbian.com/4kzongjiao//\"\n",
    "url9=\"https://pic.netbian.com\"\n",
    "r = session.get(url)\n",
    "selector='#main > div.slist'\n",
    "\n",
    "about = r.html.find(selector, first=True)\n",
    "img_Elements=about.find('img')\n",
    "img_url_lst=[url9+i.attrs['src'] for i in img_Elements]\n",
    "\n",
    "for img_url in img_url_lst:\n",
    "    \n",
    "    name = 'd:/ok/'+img_url.split('/')[-1]\n",
    "    f = open(name,'wb')\n",
    "    f.write(session.get(img_url).content)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
